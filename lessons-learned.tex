\section{Lessons Learned}
\label{sec:lesson-learned}

{\color{blue}

Here we present the lessons we learned during our semantics development, identifying important aspects to be considered, and clarifying a good practice for developing a large ISA semantics.
We also elaborate the novel aspects of our semantics development approach that allow us to obtain the complete and faithful semantics with an affordable amount of effort.

\paragraph{Regarding automatic semantics synthesis}

In Section~\ref{sec:Approach:Overview}, we reported the empirical negative result that a fully automatic synthesis of the whole \ISA semantics is not practically feasible.
Specifically, in a vast instruction set like \ISA \cmt{computer (CISC) architecture such as x86}, it is common that many instructions can be grouped together where the instructions of each group are similar to each other except for a few differences.
An automatic synthesis technique would effectively synthesize such instruction variants' semantics, provided that the semantics of its representative instruction is given in advance.\footnote{%
For certain complex instructions, the size of their group is very small (i.e., they are quite different to each other), and thus the automatic synthesis would not yield a sufficient gain over the effort of specifying the semantics of their representatives, but we found that the number of such isolated instructions of x86-64 is small.}
The problem is, however, that it is non-trivial to properly partition all the instructions into such groups, providing the representative instruction semantics for each group, \emph{without} a priori knowledge about the semantics of all instructions.
The stratification approach~\cite{Heule2016a} had been proposed to solve this dilemma, but it turned out to be not sufficient, leaving a substantial part of semantics unspecified.
Thus, we decided to manually provide the information about partition and representatives, for which we had to consult the manual to obtain knowledge about the remaining part of semantics.
Once we obtained the required knowledge, however, we realized that it would be more straightforward to directly turn the knowledge into the semantics than going through the synthesis process, and thus we ended up manually specifying the remaining part of semantics in this work.
%
This (negative) experience led us to think about a new research problem: how to obtain the prior knowledge about the semantics that is enough to partition instructions and identify their representatives, \emph{without} manually examining the entire manual.
We suggested an early idea for this problem, which we plan to develop and evaluate further as future work (Section~\ref{sec:conc}).

%As an alternative, we suggest a hybrid synthesis approach that we believe is practically promising, in particular for complex instruction set computer (CISC) architectures such as x86.
%
%While it is labor-intensive and error-prone to manually specify all the instruction variants, the automatic synthesis technique is shown to be effective to synthesize such instruction variants' semantics, provided that the semantics of its representative instruction is given in advance.
%
%Thus, in a hybrid approach, the semantics of representative instructions are manually written, and their variants are automatically synthesized. We believe that this hybrid approach is in a sweet spot, where the machine's search power and the human reasoning are effectively combined.
%We plan to apply and evaluate this idea when we specify the semantics of new instruction that will be introduced in the next version of x86-64 ISA.

Most of the previous efforts in formalizing \ISA semantics can be categorized based on whether the underlying approach is fully manual ~\cite{Goel:FMCAD14, TSL:TOPLAS13, Leroy:2009, sail-x86} or fully automatic~\cite{Heule2016a, Roessle:CPP19, Hasabnis:ASPLOS16, Hasabnis:FSE16}. We note that none of these approaches, when used in isolation, sufficiently scale to a complete and faithful semantics, as much as ours that combines these complementary approaches and benefits from each other.

Another important step of the semantics synthesis is post-processing. The generated semantics is often verbose and not necessarily human-readable. The post-processing step is desired to simplify the generated semantics to be succinct, which helps to increase the human-readability as well as to improve the efficiency when being employed in other applications (e.g., the size of SMT formula encoding can be reduced, which can reduce the burden of SMT solvers). For our semantics development, we have written dozens of simplification rules that are fed to the \K framework to simplify the synthesized semantics further (Section~\ref{sec:Approach}). 

\paragraph{Modeling and executing implementation-dependent behaviors}

Like many other programming languages, the \ISA ISA standard admits implementation-dependent behaviors, that is, each processor implementation can freely choose specific behaviors (Section~\ref{sec:challenges-in-formalizing-x86}).
There are two natural, faithful ways of specifying the implementation-dependent behaviors.
One is to parameterize the semantics over the implementation dependent behaviors, and later instantiate it with a profile that describes specific behaviors taken by the processor of interest.
Another is to introduce non-determinism in the semantics.
We took the second approach in this work, since the implementation-dependent behaviors of x86 are quite limited and mostly localized (e.g., as shown in Figure~\ref{fig:andn-semantics}).

However, the non-determinism makes it non-trivial to execute (and validate) the semantics.
For example, in the hardware co-simulation, the output of hardware execution may vary depending on the underlying processors, while the non-deterministic semantics execution will randomly choose certain behavior, which may be different from the specific behavior implemented in a processor.
To mitigate this issue, for the hardware co-simulation, we symbolically executed the semantics where the non-deterministic behaviors are represented symbolically, so that the symbolic output captures all possible behaviors, and then we checked if the hardware output is matched by (i.e., an instance of) the symbolic output. 

We note that faithfully modeling the implementation-dependent behaviors is necessary for the correctness of the semantics.
As mentioned in Section~\ref{subsec:compare-stoke}, however, Stoke~\cite{Stoke2013} does not faithfully model such behaviors, causing certain errors in their semantics that we revealed~\cite{Suppl}.
On the other hand, most of other existing \emph{direct} \ISA semantics employ an approach similar to the ones described above, faithfully modeling the implementation-dependent behaviors.
For example, Goel \etal~\cite{Goel:ProCoS17} models such behaviors using a constraint function which is guaranteed to be unique and non-deterministic, while they employ the aforementioned profiling approach for concrete execution.
TSL~\cite{TSL:TOPLAS13} makes both approaches available, from which their users can choose.

\paragraph{Employing multiple semantic engineering frameworks}

We found that employing multiple semantic frameworks is helpful. Specifically, we employed the two semantic frameworks, \K and Stoke, where we enjoyed all of their (executive) benefits that make it easier for us to write and validate the semantics, and utilize the semantics in various applications. For example, we wrote the semantics of certain complicated instructions (e.g., \instr{pcmpestri}, \instr{pcmpestrm}, and \instr{pclmulqdq}) in \K, as \K provides an easy way to specify behaviors with multiple cases, while Stoke would have required us to write a big nested if-then-else expression which is not amenable. For another example, we utilized Stoke to validate most of our instruction semantics as Stoke provides a infrastructure\footnote{Indeed, we contributed to their infrastructure as well~\cite{completing-stock,improving-stoke}.} for the hardware co-simulation, whereas we employed \K to validate the semantics of floating-point instructions as Stoke does not support executing floating-point operations while \K does.

In order to use the two frameworks interchangeably, we had to develop a translator that translates the semantics in one framework to another. To convince the correctness of the translation, we employed translation validation, where we verified equivalence between the original and the translated semantics for each instruction using the Z3 SMT solver. 

Employing multiple frameworks, with the validated translation, allowed us to utilize their exclusive features to efficiently specify (e.g., by using the well-designed specification language of one framework) and validate (e.g., by using the well-developed testing infrastructure of another framework) the semantics, which highly expedited our semantics development process, and thus significantly contributed to the completeness of our semantics.
%, not to mention the benefit of using exclusive formal analysis tools.}
%Whereas, other approaches (~\cite{Goel:FMCAD14,TSL:TOPLAS13,Leroy:2009,sail-x86,Heule2016a}) did not explore this mutual benefit to its full potential.
Moreover, employing multiple frameworks in general allows us to immediately benefit from all of their formal analysis tools, increasing the applicability of the semantics in various formal reasoning tasks.
Existing semantics development efforts (e.g., \cite{Goel:FMCAD14,Heule2016a}), however, %(~\cite{Goel:FMCAD14,TSL:TOPLAS13,Leroy:2009,sail-x86,Heule2016a})
employ a single framework without utilizing the potential of other frameworks, which otherwise might have improved completeness and/or faithfulness of their semantics with the same amount of effort.

\cmt{
We note that employing \Strata enables us to explore the near-completeness of its formalism, whereas \K framework provides many out-of-the-box formal analysis tools. The fact that we can use both the frameworks  interchangeably paid us off towards completeness and generality (in terms of using the semantics for formal analyses) of the formalism. On the other hand, other approaches (~\cite{Goel:FMCAD14,TSL:TOPLAS13,Leroy:2009,sail-x86})  did not explore this mutual benefit to its full potential\footnote{That, for some of these projects,  could be attributed to the fact getting a complete formal semantics is not the primary goal.}.
}
}
